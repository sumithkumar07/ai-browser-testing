// Test GROQ AI Model - Llama 3.3 70B Versatile
const Groq = require('groq-sdk')
require('dotenv').config()

async function testAIModel() {
  console.log('ğŸ§ª Testing GROQ AI Model - Llama 3.3 70B Versatile')
  console.log('================================================')
  
  try {
    if (!process.env.GROQ_API_KEY) {
      throw new Error('GROQ_API_KEY not found in environment')
    }
    
    const groq = new Groq({
      apiKey: process.env.GROQ_API_KEY
    })
    
    console.log('ğŸ”‘ API Key: Configured âœ…')
    console.log('ğŸ¤– Model: llama-3.3-70b-versatile')
    console.log('â±ï¸  Testing connection...\n')
    
    const startTime = Date.now()
    
    // Test AI capabilities with a complex question
    const response = await groq.chat.completions.create({
      messages: [
        {
          role: 'system',
          content: 'You are an advanced AI assistant. Demonstrate your reasoning capabilities by providing a structured, intelligent response.'
        },
        {
          role: 'user',
          content: 'Analyze the benefits of using a 70B parameter model vs an 8B parameter model for a desktop AI browser application. Be specific and technical.'
        }
      ],
      model: 'llama-3.3-70b-versatile',
      temperature: 0.7,
      max_tokens: 1024
    })
    
    const endTime = Date.now()
    const responseTime = endTime - startTime
    
    console.log('âœ… CONNECTION SUCCESSFUL!')
    console.log(`â±ï¸  Response Time: ${responseTime}ms`)
    console.log(`ğŸ“Š Tokens Used: ${response.usage?.total_tokens || 'N/A'}`)
    console.log('\nğŸ¤– AI RESPONSE:')
    console.log('================')
    console.log(response.choices[0]?.message?.content || 'No response received')
    
    console.log('\nğŸ“ˆ PERFORMANCE METRICS:')
    console.log('=======================')
    console.log(`Response Time: ${responseTime}ms`)
    console.log(`Model: ${response.model || 'llama-3.3-70b-versatile'}`)
    console.log(`Input Tokens: ${response.usage?.prompt_tokens || 'N/A'}`)
    console.log(`Output Tokens: ${response.usage?.completion_tokens || 'N/A'}`)
    console.log(`Total Tokens: ${response.usage?.total_tokens || 'N/A'}`)
    
    // Performance assessment
    console.log('\nğŸ¯ ASSESSMENT:')
    console.log('===============')
    if (responseTime < 10000) {
      console.log('âš¡ Speed: Excellent (< 10s)')
    } else if (responseTime < 20000) {
      console.log('âœ… Speed: Good (< 20s)')
    } else {
      console.log('â³ Speed: Acceptable (> 20s)')
    }
    
    const responseLength = response.choices[0]?.message?.content?.length || 0
    if (responseLength > 500) {
      console.log('ğŸ“ Response Quality: Detailed and comprehensive')
    } else if (responseLength > 200) {
      console.log('ğŸ“ Response Quality: Good depth')
    } else {
      console.log('ğŸ“ Response Quality: Basic')
    }
    
    console.log('\nğŸ‰ SUCCESS: Llama 3.3 70B Versatile is working perfectly!')
    console.log('ğŸš€ Your KAiro Browser has access to the most advanced AI model from GROQ!')
    
  } catch (error) {
    console.error('\nâŒ ERROR:', error.message)
    
    if (error.message.includes('API key')) {
      console.log('ğŸ”§ Fix: Check your GROQ_API_KEY in .env file')
    } else if (error.message.includes('model')) {
      console.log('ğŸ”§ Fix: Model may not be available or name changed')
    } else if (error.message.includes('network') || error.message.includes('fetch')) {
      console.log('ğŸ”§ Fix: Check internet connection')
    } else {
      console.log('ğŸ”§ Fix: Check GROQ service status')
    }
    
    process.exit(1)
  }
}

// Run the test
testAIModel()